import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from keras.datasets import boston_housing

# Load the dataset
(x_train, y_train), (x_test, y_test) = boston_housing.load_data()

# Convert to PyTorch tensors
x_train = torch.tensor(x_train, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)
x_test = torch.tensor(x_test, dtype=torch.float32)
y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)

# Define the model
class LinearRegressionModel(nn.Module):
    def __init__(self):
        super(LinearRegressionModel, self).__init__()
        self.linear = nn.Linear(13, 1)

    def forward(self, x):
        return self.linear(x)

# Initialize the model, loss function, and optimizer
model = LinearRegressionModel()
criterion = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)

# Train the model
num_epochs = 1000
for epoch in range(num_epochs):
    # Forward pass
    outputs = model(x_train)
    loss = criterion(outputs, y_train)
    
    # Backward pass and optimization
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    if (epoch+1) % 100 == 0:
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')

# Plotting the results
def plot_predictions(model, x, y, title):
    model.eval()
    with torch.no_grad():
        predictions = model(x).numpy()
        y = y.numpy()
        plt.scatter(y, predictions)
        plt.xlabel("Actual Prices")
        plt.ylabel("Predicted Prices")
        plt.title(title)
        plt.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=3)
        plt.show()

# Plot predictions for training set
plot_predictions(model, x_train, y_train, "Predicted vs Actual Prices (Training Set)")

# Plot predictions for test set
plot_predictions(model, x_test, y_test, "Predicted vs Actual Prices (Test Set)")

===========================================

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge, Lasso, LinearRegression
from sklearn.metrics import mean_squared_error

# Load the dataset
boston = load_boston()

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Problem 1: Implement Ridge Regression with cross-validation to select the best alpha
ridge = Ridge()
param_grid = {'alpha': np.logspace(-4, 4, 50)}
ridge_cv = GridSearchCV(ridge, param_grid, cv=5, scoring='neg_mean_squared_error')
ridge_cv.fit(X_train, y_train)

best_alpha_ridge = ridge_cv.best_params_['alpha']
ridge_best = Ridge(alpha=best_alpha_ridge)
ridge_best.fit(X_train, y_train)
y_train_pred_ridge = ridge_best.predict(X_train)
y_test_pred_ridge = ridge_best.predict(X_test)

train_mse_ridge = mean_squared_error(y_train, y_train_pred_ridge)
test_mse_ridge = mean_squared_error(y_test, y_test_pred_ridge)

print(f'Best alpha for Ridge Regression: {best_alpha_ridge}')
print(f'Train MSE (Ridge): {train_mse_ridge:.4f}')
print(f'Test MSE (Ridge): {test_mse_ridge:.4f}')

# Problem 2: Implement Lasso Regression with cross-validation to select the best alpha
lasso = Lasso(max_iter=10000)
param_grid = {'alpha': np.logspace(-4, 4, 50)}
lasso_cv = GridSearchCV(lasso, param_grid, cv=5, scoring='neg_mean_squared_error')
lasso_cv.fit(X_train, y_train)

best_alpha_lasso = lasso_cv.best_params_['alpha']
lasso_best = Lasso(alpha=best_alpha_lasso, max_iter=10000)
lasso_best.fit(X_train, y_train)
y_train_pred_lasso = lasso_best.predict(X_train)
y_test_pred_lasso = lasso_best.predict(X_test)

train_mse_lasso = mean_squared_error(y_train, y_train_pred_lasso)
test_mse_lasso = mean_squared_error(y_test, y_test_pred_lasso)

print(f'Best alpha for Lasso Regression: {best_alpha_lasso}')
print(f'Train MSE (Lasso): {train_mse_lasso:.4f}')
print(f'Test MSE (Lasso): {test_mse_lasso:.4f}')

# Problem 3: Compare the performance of Ridge, Lasso, and standard linear regression models
linear_reg = LinearRegression()
linear_reg.fit(X_train, y_train)
y_train_pred_linear = linear_reg.predict(X_train)
y_test_pred_linear = linear_reg.predict(X_test)

train_mse_linear = mean_squared_error(y_train, y_train_pred_linear)
test_mse_linear = mean_squared_error(y_test, y_test_pred_linear)

print(f'Train MSE (Linear): {train_mse_linear:.4f}')
print(f'Test MSE (Linear): {test_mse_linear:.4f}')

# Plotting the results
def plot_predictions(y_true, y_pred, title):
    plt.scatter(y_true, y_pred)
    plt.xlabel("Actual Prices")
    plt.ylabel("Predicted Prices")
    plt.title(title)
    plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--', lw=3)
    plt.show()

# Plot predictions for Linear Regression Model
plot_predictions(y_test, y_test_pred_linear, "Predicted vs Actual Prices (Test Set, Linear)")

# Plot predictions for Ridge Regression Model
plot_predictions(y_test, y_test_pred_ridge, "Predicted vs Actual Prices (Test Set, Ridge)")

# Plot predictions for Lasso Regression Model
plot_predictions(y_test, y_test_pred_lasso, "Predicted vs Actual Prices (Test Set, Lasso)")


