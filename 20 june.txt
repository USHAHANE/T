1)
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.base import BaseEstimator, RegressorMixin
import numpy as np

# Load the dataset
data = fetch_california_housing()
X, y = data.data, data.target

# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the PyTorch regression model
class LinearRegressionModel(nn.Module):
    def __init__(self, input_dim):
        super(LinearRegressionModel, self).__init__()
        self.linear = nn.Linear(input_dim, 1)
    
    def forward(self, x):
        return self.linear(x)

# Define a custom scikit-learn estimator
class PyTorchRegressor(BaseEstimator, RegressorMixin):
    def __init__(self, learning_rate=0.01, num_epochs=100):
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        self.model = None
    
    def fit(self, X, y):
        input_dim = X.shape[1]
        self.model = LinearRegressionModel(input_dim)
        criterion = nn.MSELoss()
        optimizer = optim.SGD(self.model.parameters(), lr=self.learning_rate)
        
        X_tensor = torch.tensor(X, dtype=torch.float32)
        y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)
        
        for epoch in range(self.num_epochs):
            self.model.train()
            optimizer.zero_grad()
            outputs = self.model(X_tensor)
            loss = criterion(outputs, y_tensor)
            loss.backward()
            optimizer.step()
    
    def predict(self, X):
        self.model.eval()
        X_tensor = torch.tensor(X, dtype=torch.float32)
        with torch.no_grad():
            predictions = self.model(X_tensor).numpy()
        return predictions.flatten()

# Define the grid of hyperparameters
param_grid = {
    'learning_rate': [0.001, 0.01, 0.1],
    'num_epochs': [100, 200, 500]
}

# Implement grid search using GridSearchCV
grid_search = GridSearchCV(estimator=PyTorchRegressor(), param_grid=param_grid, cv=3, scoring='neg_mean_squared_error')
grid_search.fit(X_train, y_train)

# Best hyperparameters
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Train the best model
best_model = grid_search.best_estimator_
best_model.fit(X_train, y_train)

# Make predictions
y_pred_train = best_model.predict(X_train)
y_pred_test = best_model.predict(X_test)

# Calculate regression metrics
def calculate_metrics(y_true, y_pred):
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    return mae, mse, rmse, r2

train_metrics = calculate_metrics(y_train, y_pred_train)
test_metrics = calculate_metrics(y_test, y_pred_test)

print("Train Metrics:")
print("MAE:", train_metrics[0])
print("MSE:", train_metrics[1])
print("RMSE:", train_metrics[2])
print("R-squared:", train_metrics[3])

print("\nTest Metrics:")
print("MAE:", test_metrics[0])
print("MSE:", test_metrics[1])
print("RMSE:", test_metrics[2])
print("R-squared:", test_metrics[3])

===============================================================

2)
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.base import BaseEstimator, RegressorMixin
import numpy as np
import scipy.stats as stats

# Load the dataset
data = load_boston()
X, y = data.data, data.target

# Split the dataset into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define the PyTorch regression model
class LinearRegressionModel(nn.Module):
    def __init__(self, input_dim):
        super(LinearRegressionModel, self).__init__()
        self.linear = nn.Linear(input_dim, 1)
    
    def forward(self, x):
        return self.linear(x)

# Define a custom scikit-learn estimator
class PyTorchRegressor(BaseEstimator, RegressorMixin):
    def __init__(self, learning_rate=0.01, num_epochs=100):
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        self.model = None
    
    def fit(self, X, y):
        input_dim = X.shape[1]
        self.model = LinearRegressionModel(input_dim)
        criterion = nn.MSELoss()
        optimizer = optim.SGD(self.model.parameters(), lr=self.learning_rate)
        
        X_tensor = torch.tensor(X, dtype=torch.float32)
        y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)
        
        for epoch in range(self.num_epochs):
            self.model.train()
            optimizer.zero_grad()
            outputs = self.model(X_tensor)
            loss = criterion(outputs, y_tensor)
            loss.backward()
            optimizer.step()
    
    def predict(self, X):
        self.model.eval()
        X_tensor = torch.tensor(X, dtype=torch.float32)
        with torch.no_grad():
            predictions = self.model(X_tensor).numpy()
        return predictions.flatten()

# Define the range of hyperparameters
param_dist = {
    'learning_rate': stats.loguniform(1e-4, 1e-1),
    'num_epochs': stats.randint(100, 1000)
}

# Implement random search using RandomizedSearchCV
random_search = RandomizedSearchCV(estimator=PyTorchRegressor(), param_distributions=param_dist, n_iter=10, cv=3, scoring='neg_mean_squared_error', random_state=42)
random_search.fit(X_train, y_train)

# Best hyperparameters
best_params = random_search.best_params_
print("Best Hyperparameters:", best_params)

# Train the best model
best_model = random_search.best_estimator_
best_model.fit(X_train, y_train)

# Make predictions
y_pred_train = best_model.predict(X_train)
y_pred_test = best_model.predict(X_test)

# Calculate regression metrics
def calculate_metrics(y_true, y_pred):
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    return mae, mse, rmse, r2

train_metrics = calculate_metrics(y_train, y_pred_train)
test_metrics = calculate_metrics(y_test, y_pred_test)

print("Train Metrics:")
print("MAE:", train_metrics[0])
print("MSE:", train_metrics[1])
print("RMSE:", train_metrics[2])
print("R-squared:", train_metrics[3])

print("\nTest Metrics:")
print("MAE:", test_metrics[0])
print("MSE:", test_metrics[1])
print("RMSE:", test_metrics[2])
print("R-squared:", test_metrics[3])
